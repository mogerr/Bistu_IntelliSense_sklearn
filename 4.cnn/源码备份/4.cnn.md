```python
import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils import to_categorical

# 加载MNIST数据集并进行预处理
# load_data():  Loads the MNIST dataset.
# This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. 
# More info can be found at the MNIST homepage.
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255
#转换成独热码
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 构建CNN模型
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# 展示CNN模型
model.summary()
```

    Model: "sequential_2"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       
                                                                     
     max_pooling2d_4 (MaxPoolin  (None, 13, 13, 32)        0         
     g2D)                                                            
                                                                     
     conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     
                                                                     
     max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         
     g2D)                                                            
                                                                     
     conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     
                                                                     
     flatten_2 (Flatten)         (None, 576)               0         
                                                                     
     dense_4 (Dense)             (None, 64)                36928     
                                                                     
     dense_5 (Dense)             (None, 10)                650       
                                                                     
    =================================================================
    Total params: 93322 (364.54 KB)
    Trainable params: 93322 (364.54 KB)
    Non-trainable params: 0 (0.00 Byte)
    _________________________________________________________________
    


```python

# 编译模型
# 超参数的选择
# 学习率( Learning_Rate )：学习率控制每次参数更新的步长。使用的是 adam 优化器
# 损失函数( Loss_Function ) ：损失函数衡量模型在训练过程中的性能。损失函数使用交叉熵损失函数( categorical_crossentropy )
# 度量指标( metrics )：用于度量模型在分类任务中的性能。度量指标使用 "accuracy"（准确率），
# # # 也可以使用精确度（Precision）、召回率（Recall）、F1分数、均方误差（mean squared error，MSE）等
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 训练模型
model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)

# 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels)
print("Test loss:      ", test_loss)
print("Test accuracy:  ", test_acc)


```

    Epoch 1/5
    750/750 [==============================] - 13s 16ms/step - loss: 0.2081 - accuracy: 0.9360 - val_loss: 0.0734 - val_accuracy: 0.9775
    Epoch 2/5
    750/750 [==============================] - 12s 16ms/step - loss: 0.0562 - accuracy: 0.9820 - val_loss: 0.0594 - val_accuracy: 0.9830
    Epoch 3/5
    750/750 [==============================] - 13s 17ms/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 0.0446 - val_accuracy: 0.9873
    Epoch 4/5
    750/750 [==============================] - 12s 16ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0442 - val_accuracy: 0.9869
    Epoch 5/5
    750/750 [==============================] - 12s 16ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0359 - val_accuracy: 0.9902
    313/313 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9902
    Test loss:       0.02930004894733429
    Test accuracy:   0.9901999831199646
    


```python


import numpy as np
from sklearn.metrics import precision_score, recall_score

# ...

# 在评估模型之前添加以下代码：
y_pred_prob = model.predict(test_images)
y_pred = np.argmax(y_pred_prob, axis=1)

# 评估模型
test_loss, test_acc = model.evaluate(test_images, test_labels)
print("\n")
# print("Test loss:      ", test_loss)
# print("Test accuracy:  ", test_acc)

# 准确度
print(f'Test accuracy:   {test_acc}')

# 精确度
precision = precision_score(np.argmax(test_labels, axis=1), y_pred, average='weighted')
print(f'Precision:       {precision}')

# 召回率
recall = recall_score(np.argmax(test_labels, axis=1), y_pred, average='weighted')
print(f'Recall:          {recall}')


```

    313/313 [==============================] - 1s 2ms/step
    313/313 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9902
    
    
    Test accuracy:   0.9901999831199646
    Precision:       0.9902455870131657
    Recall:          0.9902
    
